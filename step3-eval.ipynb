{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './'\n",
    "\n",
    "DATA_FILE_NAME = 'v1_data.pkl'\n",
    "#TEST_DATA_FILE_NAME = 'v1_data_test.pkl'  # contains only 500 samples\n",
    "\n",
    "VOCA_FILE_NAME = 'v1_dic.pkl'\n",
    "#GLOVE_FILE_NAME = 'v2_glove.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessData:\n",
    "    \n",
    "    def __init__(self, is_test):\n",
    "        \n",
    "        print('IS_TEST = {}'.format(str(is_test)))\n",
    "        \n",
    "        self.is_test = is_test\n",
    "        self.voca = None\n",
    "        self.pad_index = 0\n",
    "        self.index2word = {}\n",
    "        \n",
    "        self.train_set = []\n",
    "        self.valid_set = []\n",
    "        \n",
    "        self.load_data()\n",
    "        #self.create_train_set()\n",
    "        self.create_valid_set()\n",
    "        \n",
    "        \n",
    "    def load_data(self):\n",
    "        \n",
    "        if self.is_test:\n",
    "            self.train_data, self.valid_data, self.test_data = pickle.load(open(DATA_DIR + TEST_DATA_FILE_NAME, 'r'))\n",
    "            #print 'load data : ' + TEST_DATA_FILE_NAME\n",
    "        else:\n",
    "            self.train_data, self.valid_data = pickle.load(open(DATA_DIR + DATA_FILE_NAME, 'rb'))\n",
    "            #print 'load data : ' + DATA_FILE_NAME\n",
    "        \n",
    "        self.voca = pickle.load(open(DATA_DIR + VOCA_FILE_NAME, 'rb') )\n",
    "        #self.W_glove_init = pickle.load(open(DATA_DIR + GLOVE_FILE_NAME, 'r') )\n",
    "        \n",
    "        self.pad_index = self.voca['_PAD_']\n",
    "        \n",
    "        for w in self.voca:\n",
    "            self.index2word[self.voca[w]] = w\n",
    "        \n",
    "        #print '[completed] load data'\n",
    "        print(\"voca size (include _PAD_, _UNK_): {}\".format ( str( len(self.voca)) ) )\n",
    "        \n",
    "        \n",
    "    # create train set : context -> split by using '__EOS__' -> multiple sentneces\n",
    "    # convert to soucre, target, label\n",
    "    def create_train_set(self):\n",
    "        \n",
    "        data_len = len(self.train_data['c'])\n",
    "        \n",
    "        for index in range(data_len):\n",
    "            \n",
    "            turn =[x.strip() for x in (' '.join(str(e) for e in self.train_data['c'][index])).split(str(self.voca['./SF']))]\n",
    "            turn = [ x for x in turn if len(x) >1]\n",
    "            \n",
    "            tmp_ids = [x.split(' ') for x in turn]\n",
    "            source_ids = []\n",
    "            for sent in tmp_ids:\n",
    "                source_ids.append( [ int(x) for x in sent]  )\n",
    "                \n",
    "            target_ids = self.train_data['r'][index]\n",
    "            label = float(self.train_data['y'][index])\n",
    "            \n",
    "            self.train_set.append( [source_ids, target_ids, label] )\n",
    "        \n",
    "        print(\"[completed] create train set : {}\".format( str(len(self.train_set)) ) )\n",
    "        \n",
    "        \n",
    "    # create valid set : context -> split by using '__EOS__' -> multiple sentneces\n",
    "    # convert to soucre, target, label\n",
    "    def create_valid_set(self):\n",
    "        \n",
    "        data_len = len(self.valid_data['c'])\n",
    "        \n",
    "        for index in range(data_len):\n",
    "            \n",
    "            turn =[x.strip() for x in (' '.join(str(e) for e in self.valid_data['c'][index])).split(str(self.voca['./SF']))]\n",
    "            turn = [ x for x in turn if len(x) >1]\n",
    "            \n",
    "            tmp_ids = [x.split(' ') for x in turn]\n",
    "            source_ids = []\n",
    "            for sent in tmp_ids:\n",
    "                source_ids.append( [ int(x) for x in sent]  )\n",
    "                \n",
    "            target_ids = self.valid_data['r'][index]\n",
    "            label = float(self.valid_data['y'][index])\n",
    "            \n",
    "            self.valid_set.append( [source_ids, target_ids, label] )\n",
    "        \n",
    "        print(\"[completed] create valid set : {}\".format( str(len(self.valid_set)) ) )\n",
    "        \n",
    "        \n",
    "    def get_batch(self, data, batch_size, encoder_size, context_size, encoderR_size, is_test, start_index=0, target_index=1):\n",
    "\n",
    "        encoder_inputs, encoderR_inputs, encoder_seq, context_seq, encoderR_seq, target_labels = [], [], [], [], [], []\n",
    "        index = start_index\n",
    "        \n",
    "        # Get a random batch of encoder and encoderR inputs from data,\n",
    "        # pad them if needed\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "\n",
    "            if is_test is False:\n",
    "                list_encoder_input, encoderR_input, target_label = random.choice(data)\n",
    "            else:\n",
    "                list_encoder_input = data[index][0]\n",
    "                #encoderR_input = data[index][1][target_index]\n",
    "                encoderR_input = data[index][1]\n",
    "                #index = index +1\n",
    "    \n",
    "            list_len = len( list_encoder_input )\n",
    "            tmp_encoder_inputs = []\n",
    "            tmp_encoder_seq = []\n",
    "            \n",
    "            for en_input in list_encoder_input:\n",
    "                encoder_pad = [self.pad_index] * (encoder_size - len( en_input ))\n",
    "                tmp_encoder_inputs.append( (en_input + encoder_pad)[:encoder_size] )        \n",
    "                tmp_encoder_seq.append( min( len( en_input ), encoder_size ) )    \n",
    "            \n",
    "            # add pad\n",
    "            for i in range( context_size - list_len ):\n",
    "                encoder_pad = [self.pad_index] * (encoder_size)\n",
    "                tmp_encoder_inputs.append( encoder_pad )\n",
    "                tmp_encoder_seq.append( 0 ) \n",
    "\n",
    "            encoder_inputs.extend( tmp_encoder_inputs[-context_size:] )\n",
    "            encoder_seq.extend( tmp_encoder_seq[-context_size:] )\n",
    "            \n",
    "            context_seq.append( min(  len(list_encoder_input), context_size  ) )\n",
    "\n",
    "            # encoderR inputs are padded\n",
    "            encoderR_pad = [self.pad_index] * (encoderR_size - len(encoderR_input))\n",
    "            encoderR_inputs.append( (encoderR_input + encoderR_pad)[:encoderR_size]) \n",
    "\n",
    "            encoderR_seq.append( min(len(encoderR_input), encoderR_size) )\n",
    "\n",
    "            # Target Label for batch\n",
    "            if is_test is False:\n",
    "                target_labels.append( int(target_label) )\n",
    "            else:\n",
    "                target_labels.append( int(data[index][2]) )\n",
    "                index = index + 1\n",
    "                #if target_index is 0:\n",
    "                #    target_labels.append( int(1) )\n",
    "                #else:\n",
    "                #    target_labels.append( int(0) )\n",
    "                    \n",
    "                    \n",
    "        return encoder_inputs, encoderR_inputs, encoder_seq, context_seq, encoderR_seq, np.reshape(target_labels, (batch_size, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "encoder_size=80\n",
    "context_size=15\n",
    "encoderR_size=160\n",
    "\n",
    "# siaseme RNN\n",
    "num_layer=1\n",
    "hidden_dim=300\n",
    "\n",
    "# context RNN\n",
    "num_layer_con=1\n",
    "hidden_dim_con=300\n",
    "\n",
    "embed_size=300\n",
    "#num_train_steps=100000\n",
    "lr=0.001\n",
    "#valid_freq=500\n",
    "#is_save=1\n",
    "#graph_prefix='HRDE_LTC_korquad_v1_'\n",
    "\n",
    "#is_test=0\n",
    "#use_glove=0\n",
    "\n",
    "#dr=0.3\n",
    "#dr_con=1.0\n",
    "#memory_dr=0.8\n",
    "\n",
    "# latent topic\n",
    "memory_dim=256\n",
    "topic_size=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS_TEST = False\n",
      "voca size (include _PAD_, _UNK_): 149724\n",
      "[completed] create valid set : 15414\n"
     ]
    }
   ],
   "source": [
    "batch_gen = ProcessData(is_test=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HRDE_Model_mem_v1 import *\n",
    "from HRDE_evaluation import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HRDualEncoderModel(voca_size=len(batch_gen.voca),\n",
    "                               batch_size=batch_size,\n",
    "                               encoder_size=encoder_size,\n",
    "                               context_size=context_size,\n",
    "                               encoderR_size=encoderR_size,\n",
    "                               num_layer=num_layer,                 \n",
    "                               hidden_dim=hidden_dim,\n",
    "                               num_layer_con=num_layer_con,\n",
    "                               hidden_dim_con=hidden_dim_con,\n",
    "                               lr=lr,\n",
    "                               embed_size=embed_size,\n",
    "                               use_glove = 0,\n",
    "                               dr=1.0,\n",
    "                               dr_con=1.0,\n",
    "                               memory_dr = 1.0,\n",
    "                               memory_dim = memory_dim,\n",
    "                               topic_size=topic_size\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[launch] create placeholders\n",
      "[launch] create embedding\n",
      "[launch] create gru model\n",
      "[launch] add memory network - 1st version / without output projection\n",
      "WARNING:tensorflow:From /home/dlwkddnjsa/project/HRDE_LTC/korquad/HRDE_Model_mem_v1.py:275: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "WARNING:tensorflow:From /home/dlwkddnjsa/project/HRDE_LTC/korquad/HRDE_Model_mem_v1.py:280: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "[launch] create output projection layer\n",
      "[launch] create optimizer\n",
      "[launch] create summary\n"
     ]
    }
   ],
   "source": [
    "model.build_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./save/HRDE_LTC_korquad_v1__b256_es80_eRs160_cs15_L1_H300_Lc1_Hc300_G0_dr0.3_drc1.0_drM0.8_M256_T3/\n"
     ]
    }
   ],
   "source": [
    "path = './save/'\n",
    "\n",
    "list_dir = os.listdir(path)\n",
    "list_hrde_mem = list_dir[0]\n",
    "target_dir = path + list_hrde_mem + '/'\n",
    "print(target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from check point!!!\n",
      "INFO:tensorflow:Restoring parameters from ./save/HRDE_LTC_korquad_v1__b256_es80_eRs160_cs15_L1_H300_Lc1_Hc300_G0_dr0.3_drc1.0_drM0.8_M256_T3/-13500\n",
      "0.6897727559010188\n",
      "0.8077473958333333\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "summary = None\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(target_dir ))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print ('from check point!!!')\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    num_corr = 0\n",
    "    sum_loss = 0.0\n",
    "    \n",
    "    itr_loop = len(batch_gen.valid_set) / model.batch_size\n",
    "\n",
    "    for test_itr in range( int(itr_loop) ):\n",
    "\n",
    "        raw_encoder_inputs, raw_encoderR_inputs, raw_encoder_seq, raw_context_seq, raw_encoderR_seq, raw_target_label = batch_gen.get_batch(\n",
    "                                                                    data=batch_gen.valid_set,\n",
    "                                                                    batch_size=model.batch_size,\n",
    "                                                                    encoder_size=model.encoder_size,\n",
    "                                                                    context_size = model.context_size,\n",
    "                                                                    encoderR_size=model.encoderR_size,\n",
    "                                                                    is_test=True,\n",
    "                                                                    start_index= (test_itr* model.batch_size))\n",
    "\n",
    "\n",
    "        # prepare data which will be push from pc to placeholder\n",
    "        input_feed = {}\n",
    "\n",
    "        input_feed[model.encoder_inputs] = raw_encoder_inputs\n",
    "        input_feed[model.encoderR_inputs] = raw_encoderR_inputs\n",
    "\n",
    "        input_feed[model.encoder_seq_length] = raw_encoder_seq\n",
    "        input_feed[model.context_seq_length] = raw_context_seq\n",
    "        input_feed[model.encoderR_seq_length] = raw_encoderR_seq\n",
    "\n",
    "        input_feed[model.y_label] = raw_target_label\n",
    "\n",
    "        input_feed[model.dr_prob] = 1.0          # no drop out while evaluating\n",
    "        input_feed[model.dr_prob_con] = 1.0   # no drop out while evaluating \n",
    "        input_feed[model.dr_memory_prob] = 1.0\n",
    "\n",
    "        try:\n",
    "            bprob, b_loss, lo = sess.run([model.batch_prob, model.batch_loss, model.loss], input_feed)\n",
    "        except:\n",
    "            print(\"excepetion occurs in valid step : {}\".format(str(test_itr)))\n",
    "            pass\n",
    "\n",
    "        for idx, prob in enumerate(bprob):\n",
    "            if prob > 0.5:\n",
    "                if raw_target_label[idx] == 1:\n",
    "                    num_corr = num_corr + 1\n",
    "            else:\n",
    "                if raw_target_label[idx] == 0:\n",
    "                    num_corr = num_corr + 1\n",
    "\n",
    "        sum_loss = sum_loss + lo\n",
    "\n",
    "    avg_ce = sum_loss / int(itr_loop)\n",
    "    avg_accr = num_corr / ( int(itr_loop) * model.batch_size )\n",
    "    \n",
    "    print(avg_ce)\n",
    "    print(avg_accr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
